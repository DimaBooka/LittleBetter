views.py [LINE:68]# INFO [2016-09-21 11:54:12,490] Successfully processed request.
server.py [LINE:63]# INFO [2016-09-21 11:54:18,245] Successes query to Redis.
protocol.py [LINE:899]# INFO [2016-09-21 11:54:18,245] Redis connection lost
views.py [LINE:68]# INFO [2016-09-21 11:54:18,270] Successfully processed request.
views.py [LINE:68]# INFO [2016-09-21 11:54:23,049] Successfully processed request.
server.py [LINE:83]# INFO [2016-09-21 12:28:06,682] Autobahn successfully connected to port.
views.py [LINE:68]# INFO [2016-09-21 12:35:46,922] Successfully processed request.
views.py [LINE:38]# INFO [2016-09-21 12:35:48,439] Entered query is OK.
connectionpool.py [LINE:214]# INFO [2016-09-21 12:35:48,517] Starting new HTTP connection (1): 0.0.0.0
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:35:49,630] "GET /listspiders.json?project=links_finder HTTP/1.1" 200 85
scrapyd_file.py [LINE:34]# INFO [2016-09-21 12:35:49,631] Сonnected to Scrapyd.
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:35:49,773] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:35:49,773] Activated google spider. ----- so
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:35:49,923] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:35:49,923] Activated instagram spider. ----- so
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:35:49,998] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:35:49,999] Activated yandex spider. ----- so
server.py [LINE:19]# INFO [2016-09-21 12:35:50,476] Client successes connected.
server.py [LINE:23]# INFO [2016-09-21 12:35:50,476] WebSocket connection open.
connection.py [LINE:99]# INFO [2016-09-21 12:35:50,483] Connecting to redis
protocol.py [LINE:821]# INFO [2016-09-21 12:35:50,484] Redis connection made
views.py [LINE:68]# INFO [2016-09-21 12:35:50,495] Successfully processed request.
server.py [LINE:99]# INFO [2016-09-21 12:36:22,587] Successfully disconnected to port.
server.py [LINE:67]# ERROR [2016-09-21 12:36:22,604] Could'not connect to Redis.
base_events.py [LINE:1148]# ERROR [2016-09-21 12:36:22,605] Task was destroyed but it is pending!
task: <Task pending coro=<MyServerProtocol.onMessage() running at /home/user/PycharmProjects/Exam_task/server.py:67> wait_for=<Future cancelled>>
base_events.py [LINE:1148]# ERROR [2016-09-21 12:36:22,605] Task was destroyed but it is pending!
task: <Task pending coro=<RedisProtocol._reader_coroutine() done, defined at /home/user/PycharmProjects/Exam_task/django_part/.env/lib/python3.5/site-packages/asyncio_redis/protocol.py:934> wait_for=<Future pending cb=[Task._wakeup()]>>
server.py [LINE:83]# INFO [2016-09-21 12:36:25,059] Autobahn successfully connected to port.
views.py [LINE:68]# INFO [2016-09-21 12:37:21,140] Successfully processed request.
views.py [LINE:38]# INFO [2016-09-21 12:37:24,778] Entered query is OK.
connectionpool.py [LINE:214]# INFO [2016-09-21 12:37:24,781] Starting new HTTP connection (1): 0.0.0.0
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:37:25,303] "GET /listspiders.json?project=links_finder HTTP/1.1" 200 85
scrapyd_file.py [LINE:34]# INFO [2016-09-21 12:37:25,303] Сonnected to Scrapyd.
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:37:25,382] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:37:25,383] Activated google spider. ----- so what
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:37:25,449] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:37:25,450] Activated instagram spider. ----- so what
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:37:25,524] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:37:25,525] Activated yandex spider. ----- so what
server.py [LINE:19]# INFO [2016-09-21 12:37:25,945] Client successes connected.
server.py [LINE:23]# INFO [2016-09-21 12:37:25,946] WebSocket connection open.
connection.py [LINE:99]# INFO [2016-09-21 12:37:25,967] Connecting to redis
protocol.py [LINE:821]# INFO [2016-09-21 12:37:25,968] Redis connection made
views.py [LINE:68]# INFO [2016-09-21 12:37:25,984] Successfully processed request.
server.py [LINE:99]# INFO [2016-09-21 12:38:41,805] Successfully disconnected to port.
server.py [LINE:67]# ERROR [2016-09-21 12:38:41,815] Could'not connect to Redis.
base_events.py [LINE:1148]# ERROR [2016-09-21 12:38:41,815] Task was destroyed but it is pending!
task: <Task pending coro=<MyServerProtocol.onMessage() running at /home/user/PycharmProjects/Exam_task/server.py:67> wait_for=<Future cancelled>>
base_events.py [LINE:1148]# ERROR [2016-09-21 12:38:41,816] Task was destroyed but it is pending!
task: <Task pending coro=<RedisProtocol._reader_coroutine() done, defined at /home/user/PycharmProjects/Exam_task/django_part/.env/lib/python3.5/site-packages/asyncio_redis/protocol.py:934> wait_for=<Future pending cb=[Task._wakeup()]>>
server.py [LINE:84]# INFO [2016-09-21 12:38:42,127] Autobahn successfully connected to port.
views.py [LINE:68]# INFO [2016-09-21 12:38:48,513] Successfully processed request.
views.py [LINE:38]# INFO [2016-09-21 12:38:50,993] Entered query is OK.
connectionpool.py [LINE:214]# INFO [2016-09-21 12:38:50,996] Starting new HTTP connection (1): 0.0.0.0
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:38:50,999] "GET /listspiders.json?project=links_finder HTTP/1.1" 200 85
scrapyd_file.py [LINE:34]# INFO [2016-09-21 12:38:51,000] Сonnected to Scrapyd.
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:38:51,178] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:38:51,179] Activated google spider. ----- asfvv
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:38:51,253] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:38:51,254] Activated instagram spider. ----- asfvv
connectionpool.py [LINE:401]# DEBUG [2016-09-21 12:38:51,328] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 12:38:51,329] Activated yandex spider. ----- asfvv
server.py [LINE:19]# INFO [2016-09-21 12:38:51,697] Client successes connected.
server.py [LINE:23]# INFO [2016-09-21 12:38:51,697] WebSocket connection open.
connection.py [LINE:99]# INFO [2016-09-21 12:38:51,712] Connecting to redis
protocol.py [LINE:821]# INFO [2016-09-21 12:38:51,713] Redis connection made
server.py [LINE:68]# ERROR [2016-09-21 12:38:51,714] Could'not connect to Redis.
views.py [LINE:68]# INFO [2016-09-21 12:38:51,721] Successfully processed request.
server.py [LINE:100]# INFO [2016-09-21 13:53:13,238] Successfully disconnected to port.
base_events.py [LINE:1148]# ERROR [2016-09-21 13:53:13,249] Task was destroyed but it is pending!
task: <Task pending coro=<RedisProtocol._reader_coroutine() done, defined at /home/user/PycharmProjects/Exam_task/django_part/.env/lib/python3.5/site-packages/asyncio_redis/protocol.py:934> wait_for=<Future pending cb=[Task._wakeup()]>>
server.py [LINE:85]# INFO [2016-09-21 13:53:13,586] Autobahn successfully connected to port.
views.py [LINE:68]# INFO [2016-09-21 13:53:59,287] Successfully processed request.
views.py [LINE:38]# INFO [2016-09-21 13:54:03,979] Entered query is OK.
connectionpool.py [LINE:214]# INFO [2016-09-21 13:54:03,983] Starting new HTTP connection (1): 0.0.0.0
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:03,986] "GET /listspiders.json?project=links_finder HTTP/1.1" 200 85
scrapyd_file.py [LINE:34]# INFO [2016-09-21 13:54:03,987] Сonnected to Scrapyd.
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:04,165] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 13:54:04,166] Activated google spider. ----- awf
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:04,240] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 13:54:04,241] Activated instagram spider. ----- awf
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:04,315] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 13:54:04,316] Activated yandex spider. ----- awf
server.py [LINE:19]# INFO [2016-09-21 13:54:04,689] Client successes connected.
server.py [LINE:23]# INFO [2016-09-21 13:54:04,689] WebSocket connection open.
connection.py [LINE:99]# INFO [2016-09-21 13:54:04,696] Connecting to redis
protocol.py [LINE:821]# INFO [2016-09-21 13:54:04,697] Redis connection made
server.py [LINE:69]# ERROR [2016-09-21 13:54:04,698] Could'not connect to Redis.
views.py [LINE:68]# INFO [2016-09-21 13:54:04,723] Successfully processed request.
server.py [LINE:101]# INFO [2016-09-21 13:54:32,278] Successfully disconnected to port.
base_events.py [LINE:1148]# ERROR [2016-09-21 13:54:32,291] Task was destroyed but it is pending!
task: <Task pending coro=<RedisProtocol._reader_coroutine() done, defined at /home/user/PycharmProjects/Exam_task/django_part/.env/lib/python3.5/site-packages/asyncio_redis/protocol.py:934> wait_for=<Future pending cb=[Task._wakeup()]>>
server.py [LINE:85]# INFO [2016-09-21 13:54:32,535] Autobahn successfully connected to port.
views.py [LINE:38]# INFO [2016-09-21 13:54:37,427] Entered query is OK.
views.py [LINE:68]# INFO [2016-09-21 13:54:37,440] Successfully processed request.
views.py [LINE:68]# INFO [2016-09-21 13:54:40,469] Successfully processed request.
views.py [LINE:38]# INFO [2016-09-21 13:54:47,096] Entered query is OK.
connectionpool.py [LINE:214]# INFO [2016-09-21 13:54:47,098] Starting new HTTP connection (1): 0.0.0.0
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:47,100] "GET /listspiders.json?project=links_finder HTTP/1.1" 200 85
scrapyd_file.py [LINE:34]# INFO [2016-09-21 13:54:47,101] Сonnected to Scrapyd.
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:48,072] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 13:54:48,073] Activated google spider. ----- 123
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:48,189] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 13:54:48,189] Activated instagram spider. ----- 123
connectionpool.py [LINE:401]# DEBUG [2016-09-21 13:54:48,331] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 13:54:48,332] Activated yandex spider. ----- 123
server.py [LINE:19]# INFO [2016-09-21 13:54:48,786] Client successes connected.
server.py [LINE:23]# INFO [2016-09-21 13:54:48,786] WebSocket connection open.
connection.py [LINE:99]# INFO [2016-09-21 13:54:48,805] Connecting to redis
protocol.py [LINE:821]# INFO [2016-09-21 13:54:48,806] Redis connection made
server.py [LINE:69]# ERROR [2016-09-21 13:54:48,806] Could'not connect to Redis.
views.py [LINE:68]# INFO [2016-09-21 13:54:48,825] Successfully processed request.
server.py [LINE:101]# INFO [2016-09-21 14:00:36,873] Successfully disconnected to port.
base_events.py [LINE:1148]# ERROR [2016-09-21 14:00:36,886] Task was destroyed but it is pending!
task: <Task pending coro=<RedisProtocol._reader_coroutine() done, defined at /home/user/PycharmProjects/Exam_task/django_part/.env/lib/python3.5/site-packages/asyncio_redis/protocol.py:934> wait_for=<Future pending cb=[Task._wakeup()]>>
server.py [LINE:84]# INFO [2016-09-21 14:00:37,140] Autobahn successfully connected to port.
server.py [LINE:100]# INFO [2016-09-21 14:01:57,991] Successfully disconnected to port.
server.py [LINE:85]# INFO [2016-09-21 14:01:58,329] Autobahn successfully connected to port.
views.py [LINE:38]# INFO [2016-09-21 14:02:01,632] Entered query is OK.
views.py [LINE:68]# INFO [2016-09-21 14:02:01,642] Successfully processed request.
views.py [LINE:38]# INFO [2016-09-21 14:02:04,462] Entered query is OK.
connectionpool.py [LINE:214]# INFO [2016-09-21 14:02:04,464] Starting new HTTP connection (1): 0.0.0.0
connectionpool.py [LINE:401]# DEBUG [2016-09-21 14:02:04,466] "GET /listspiders.json?project=links_finder HTTP/1.1" 200 85
scrapyd_file.py [LINE:34]# INFO [2016-09-21 14:02:04,467] Сonnected to Scrapyd.
connectionpool.py [LINE:401]# DEBUG [2016-09-21 14:02:04,674] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 14:02:04,675] Activated google spider. ----- 265
connectionpool.py [LINE:401]# DEBUG [2016-09-21 14:02:04,766] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 14:02:04,766] Activated instagram spider. ----- 265
connectionpool.py [LINE:401]# DEBUG [2016-09-21 14:02:04,848] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 14:02:04,849] Activated yandex spider. ----- 265
server.py [LINE:19]# INFO [2016-09-21 14:02:05,307] Client successes connected.
server.py [LINE:23]# INFO [2016-09-21 14:02:05,307] WebSocket connection open.
connection.py [LINE:99]# INFO [2016-09-21 14:02:05,316] Connecting to redis
protocol.py [LINE:821]# INFO [2016-09-21 14:02:05,317] Redis connection made
views.py [LINE:68]# INFO [2016-09-21 14:02:05,323] Successfully processed request.
server.py [LINE:67]# INFO [2016-09-21 14:02:17,462] Successes query to Redis.
protocol.py [LINE:899]# INFO [2016-09-21 14:02:17,463] Redis connection lost
views.py [LINE:68]# INFO [2016-09-21 14:02:17,480] Successfully processed request.
views.py [LINE:68]# INFO [2016-09-21 14:02:23,667] Successfully processed request.
server.py [LINE:84]# INFO [2016-09-21 16:45:27,226] Autobahn successfully connected to port.
server.py [LINE:101]# INFO [2016-09-21 16:45:33,825] Successfully disconnected to port.
server.py [LINE:84]# INFO [2016-09-21 16:45:38,336] Autobahn successfully connected to port.
views.py [LINE:68]# INFO [2016-09-21 16:46:59,220] Successfully processed request.
views.py [LINE:38]# INFO [2016-09-21 16:47:03,545] Entered query is OK.
connectionpool.py [LINE:214]# INFO [2016-09-21 16:47:03,550] Starting new HTTP connection (1): 0.0.0.0
connectionpool.py [LINE:401]# DEBUG [2016-09-21 16:47:03,552] "GET /listspiders.json?project=links_finder HTTP/1.1" 200 85
scrapyd_file.py [LINE:34]# INFO [2016-09-21 16:47:03,553] Сonnected to Scrapyd.
connectionpool.py [LINE:401]# DEBUG [2016-09-21 16:47:03,744] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 16:47:03,745] Activated google spider. ----- shader
connectionpool.py [LINE:401]# DEBUG [2016-09-21 16:47:03,819] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 16:47:03,820] Activated instagram spider. ----- shader
connectionpool.py [LINE:401]# DEBUG [2016-09-21 16:47:03,894] "POST /schedule.json HTTP/1.1" 200 84
scrapyd_file.py [LINE:43]# INFO [2016-09-21 16:47:03,894] Activated yandex spider. ----- shader
server.py [LINE:19]# INFO [2016-09-21 16:47:04,232] Client successes connected.
server.py [LINE:23]# INFO [2016-09-21 16:47:04,233] WebSocket connection open.
connection.py [LINE:99]# INFO [2016-09-21 16:47:04,297] Connecting to redis
protocol.py [LINE:821]# INFO [2016-09-21 16:47:04,298] Redis connection made
views.py [LINE:68]# INFO [2016-09-21 16:47:04,310] Successfully processed request.
server.py [LINE:66]# INFO [2016-09-21 16:47:17,767] Successes query to Redis.
protocol.py [LINE:899]# INFO [2016-09-21 16:47:17,767] Redis connection lost
views.py [LINE:68]# INFO [2016-09-21 16:47:17,786] Successfully processed request.
views.py [LINE:68]# INFO [2016-09-21 16:47:24,063] Successfully processed request.
